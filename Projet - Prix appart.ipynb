{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08952cd0",
   "metadata": {},
   "source": [
    "# Projet Technique de programmation : Marché de l'immobilier de Strasbourg\n",
    "\n",
    "L'objectif est de créer un programme pouvant extraire des données des annonces de bien immobilier.  \n",
    "Ces données nous servirons à :  \n",
    "    - Estimer le prix d'un bien immobilier selon certaines caractéristiques.  \n",
    "    - Trier les annonces afin d'obtenir des recommandations d'annonce selon des critiques définit par l'utilisateur.  \n",
    "    - Etablir un panorama du marché immobilier et un suivi de son évolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656fa31",
   "metadata": {},
   "source": [
    "# I. Fonctions et packages globaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a182d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des packages que nous allons utiliser dans ce script\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time \n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d5323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de récuperer le code html d'un page internet\n",
    "# ATTENTION : IL FAUT MODIFIER L'USER AGENT !!!!!!\n",
    "\n",
    "def get_page(urlpage):\n",
    "    user_agent = {'User-Agent':''}\n",
    "    # Timer qui retard l'envoi de requête vers le site pour pas se faire ban\n",
    "    time.sleep(0.2 + np.random.rand()/10)\n",
    "    res = requests.get(urlpage, headers = user_agent)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb52d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui nous permet de récupérer les liens des annonces des logements\n",
    "# Les sites disponibles sont \"orpi\" et \"nexity\"\n",
    "\n",
    "def get_link(site):\n",
    "    # On récupère les caractèristiques pour le site 'orpi'\n",
    "    if (site=='orpi')==True:\n",
    "        urlpage = 'https://www.orpi.com/location-immobiliere-strasbourg/louer-appartement/' # url\n",
    "        a = \"a\" # la balise\n",
    "        b = 'u-link-unstyled c-overlay__link' # la classe\n",
    "        website = \"https://www.orpi.com\" # le lien du site web\n",
    "        reg = 'href=\"(.*?)\">\\n<span' # la regular expression qui encadre notre lien\n",
    "    # On récupère les caractéristiques pour le site 'nexity'\n",
    "    if (site=='nexity')==True:\n",
    "        urlpage = 'https://www.nexity.fr/annonces-immobilieres/location/appartement/tout/strasbourg+67' # url\n",
    "        a = \"div\" # la balise\n",
    "        b = 'product-card-content flex flex-column align-items-start' # la classe\n",
    "        website = \"https://www.nexity.fr\" # le lien du site web\n",
    "        reg = 'href=\"(.*?)\" target' # la regular expression qui encadre notre lien\n",
    "    \n",
    "    # On charge la page d'acceuil ou toutes les annonces sont énumérées\n",
    "    soup = get_page(urlpage) \n",
    "    # On recupère les infos dans le html\n",
    "    annonces = soup.find_all(a, class_= b)\n",
    "    # On initialise un vecteur vide pour stocker les liens des annonces\n",
    "    links = []\n",
    "    \n",
    "    for i in range(len(annonces)):\n",
    "        text = str(annonces[i]) #On met chaque annonce en chaine de caractère\n",
    "        link = re.findall(reg, text)[0] # On cherche la regular expression qu'on a définit plsu haut\n",
    "        path = website + link # On regroupe le nom du site et le nom de l'annonce\n",
    "        links.append(path) # On l'ajoute à notre vecteur \"links\"\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfcf76f",
   "metadata": {},
   "source": [
    "# II. Scraping \"Orpi\"\n",
    "https://www.orpi.com/location-immobiliere-strasbourg/louer-appartement/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f742e",
   "metadata": {},
   "source": [
    "## 1. Fonctions pour récupérer les caractéristiques des annonces Orpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c1e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Récupération du type : appartement ou maison\n",
    "def get_type(soup):\n",
    "    text = soup.find_all(\"span\", class_='u-block@sm u-block@md-plus')[0].text\n",
    "    if (text.find(\"Appartement\") != -1) == True:\n",
    "        typ = \"Appartement\"\n",
    "    elif (text.find(\"Maison\") != -1) == True:\n",
    "        typ = \"Maison\"\n",
    "    return [typ]\n",
    "\n",
    "# b) Récupération de la ville : Strasbourg et alentour\n",
    "def get_ville(soup):\n",
    "    text = soup.find(\"span\", class_='u-h3 u-ml-xs u-text-normal').text\n",
    "    return [text]\n",
    "\n",
    "# c) Loyer et Charges\n",
    "def get_loyer_charges(soup): \n",
    "    text = soup.find(\"ul\", class_='u-list-unstyled u-text-xs u-mt-xs u-color-text-grey').find_all('li')\n",
    "    for i in range(len(text)):\n",
    "        et = text[i].text\n",
    "        if \"Loyer\" in et:\n",
    "            loyer = str(int(''.join(re.findall(r'\\d', et))))\n",
    "        if \"Provisions\" in et:\n",
    "            prov = str(int(''.join(re.findall(r'\\d', et))))\n",
    "    return [loyer, prov]\n",
    "\n",
    "# d) Nombre de pièce et surface\n",
    "def get_piece(soup):\n",
    "    text = soup.find_all(\"span\", class_='u-block@sm u-block@md-plus')[1].text.replace(\" \", \"\")\n",
    "    piece = re.findall(r'\\n(.*?)pièce', text)\n",
    "    surface = re.findall(r'•(.*?)m2', text)\n",
    "    return piece + surface\n",
    "\n",
    "# e) Caractéristiques spécifiques (Meublé, Ascenseur, Balcon, Terrasse, Jardin, Stationnement, Cave, Étage)\n",
    "def get_caracteristiques(soup):\n",
    "    obj = [\"Meublé\", \"Ascenseur\", \"Balcon\", \"Jardin\", \"Terrasse\", \"Stationnement\", \"Cave\", \"Étage\"]\n",
    "    text = soup.find_all(class_='u-flex u-flex-cross-center')\n",
    "    element = []\n",
    "    crtqs = [\"Non\"] * len(obj)\n",
    "    for i in range(len(text)-1):\n",
    "        piece = text[i].find(\"span\").text\n",
    "        element.append(piece)\n",
    "\n",
    "    for i in range(len(obj)):\n",
    "        for j in range(len(element)):\n",
    "            if obj[i] in element[j]:\n",
    "                if (obj[i]==\"Étage\")==True:\n",
    "                    crtqs[i] = element[j].split()[1]\n",
    "                else:\n",
    "                    crtqs[i] = \"Oui\"\n",
    "                    break\n",
    "    return crtqs\n",
    "\n",
    "# f) Récupération du quartier\n",
    "def get_quartier(soup):\n",
    "    text = soup.find_all(\"h2\", class_='u-h3')\n",
    "    if (get_ville(soup) == [\"Strasbourg\"])==True: # Si la ville est strasbourg, on récupère le quartier\n",
    "        for i in range(len(text)):\n",
    "            et = text[i].text\n",
    "            if \"Quartier\" in et:\n",
    "                localisation = re.findall(r'Quartier (.*?) à', et)\n",
    "    else: # Si la ville n'est pas strasbourg, le nom du quartier sera le nom de la ville\n",
    "        localisation = get_ville(soup)\n",
    "    return localisation\n",
    "\n",
    "# g) Récupération de la consommation annuelle d'énergie et d'emission de gaz à effet de serre\n",
    "# Ici on sépare la fonction en 3 cas : Si aucune info sur l'énergie est dispo, si une seule info et dispo et si la \n",
    "# consommation et les emissions de GES sont disponibles.\n",
    "# L'idée ici est de récuperer le vecteur avec les lettres et la consommation dans l'annonce et de regarder si est différent\n",
    "# de celui de référence.\n",
    "def get_conso(soup):\n",
    "    vecteur = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"] # Vecteur des classes énergies\n",
    "    text = soup.find_all(\"ul\", class_='c-dpe')\n",
    "    \n",
    "    if (len(text)==0)==True: # Si aucune info est disponible dans l'annonce\n",
    "        nrj = [\"NA\", \"NA\"]\n",
    "    \n",
    "    elif (len(text)==1)==True: # Si une seule info est disponible\n",
    "            et = text[0].text\n",
    "            resultats = re.findall(r'[A-Za-z]+|\\d+|kWh/m2\\.an', et)\n",
    "            for i in range(len(resultats)):\n",
    "                if (resultats[i] == vecteur[i]) == False:\n",
    "                    for resultat in resultats:\n",
    "                        if (resultat == 'kWh') == True:\n",
    "                            nrj = [resultats[i], \"NA\"]\n",
    "                        elif (resultat == 'kgeqCO') == True:\n",
    "                            nrj = [\"NA\", resultats[i]]\n",
    "                    break\n",
    "\n",
    "    elif (len(text)==2)==True:\n",
    "        for i in range(len(text)): # Si les deux sont disponibles dans l'annonce\n",
    "            et = text[i].text\n",
    "            resultats = re.findall(r'[A-Za-z]+|\\d+|kWh/m2\\.an', et)\n",
    "            for i in range(len(resultats)):\n",
    "                if (resultats[i] == vecteur[i]) == False:\n",
    "                    for resultat in resultats:\n",
    "                        if (resultat == 'kWh') == True:\n",
    "                            nrj = resultats[i]\n",
    "                        if (resultat == 'kgeqCO') == True:\n",
    "                            ges = resultats[i]\n",
    "                    break\n",
    "                    \n",
    "        nrj = [nrj, ges]\n",
    "    return nrj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0fb4ac",
   "metadata": {},
   "source": [
    "## 2. Fonction pour une annonce Orpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc13c9e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fonction qui nous donne toutes les caractéristiques de l'annonce orpi à l'aide des fonction précédente \n",
    "def get_orpi(urlpage):\n",
    "    user_agent = {'User-Agent':''}\n",
    "    soup = get_page(urlpage)\n",
    "    appart = get_type(soup) + get_ville(soup) + get_quartier(soup) + get_loyer_charges(soup) + get_piece(soup) + get_caracteristiques(soup) + get_conso(soup)\n",
    "    return appart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf66ca",
   "metadata": {},
   "source": [
    "# III. Scraping Nexity\n",
    "https://www.nexity.fr/location/FL0790538/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f62ce",
   "metadata": {},
   "source": [
    "## 1. Fonctions pour les caractéristiques des annonces Nexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a357d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Récupération de la ville\n",
    "def get_ville_nexity(soup):\n",
    "    text = soup.find(\"span\", class_='city').text\n",
    "    return [text]\n",
    "\n",
    "# b) Récupération du quartier\n",
    "# Sur Nexity, on a pas accès à la variable quartier, on doit donc regarder dans le texte de description si les noms de \n",
    "# quartier ci dessous sont évoqués.\n",
    "def get_quartier_nexity(soup):\n",
    "    quartiers = [\"meinau\", \"neustadt\", \"esplanade\", \"petite france\", \"cronenbourg\", \"koenigshoffen\", \"halles\", \"neudorf\", \"robertsau\", \"gare\", \"musau\", \"orangerie\", \"krutenau\", \"forêt noire\"]\n",
    "    quartier = 0\n",
    "    text = soup.find(\"div\", class_='description text_body_1 mt-2').text\n",
    "    text = text.lower().split()\n",
    "    for i in range(len(quartiers)):\n",
    "        for j in range(len(text)):\n",
    "            if (text[j] == quartiers[i])==True:\n",
    "                quartier = quartiers[i].capitalize()\n",
    "                break\n",
    "        if (quartier == 0) == True:\n",
    "            quartier = \"NA\"\n",
    "    return [quartier]\n",
    "\n",
    "# c) Caractéristiques spécifiques (Type, Loyer, Charges, Pièces, Surface, Ascenseur, Balcon, Terrain, Terrasse, Parking, \n",
    "#                                  Cave, Etage) \n",
    "def get_carac_nexity(soup, word):\n",
    "    text = soup.find_all(\"div\", class_='d-flex align-items-center')\n",
    "    var = 'R'\n",
    "    for i in range(len(text)):\n",
    "        et = text[i].text.lower()\n",
    "        et1 = et.split()\n",
    "        if (et.find(word) != -1) == True:\n",
    "            if (word == \"etage\")==True:\n",
    "                var = et1[1]\n",
    "            else:\n",
    "                var = et1[len(et1)-1].capitalize()\n",
    "            break\n",
    "            break\n",
    "    if (var==\"R\")==True:\n",
    "        var = \"NA\"\n",
    "    return [var] \n",
    "\n",
    "# d) Performance énergétique\n",
    "def get_nrj_nexity(soup):\n",
    "    text = soup.find_all(\"div\", class_='item-indice--value indice-dpe')\n",
    "    if (text==[])==True:\n",
    "        text = soup.find_all(\"div\", class_='item-indice--value indice-dpe--f-or-g')\n",
    "    dpe = [text[0].find(\"span\").text]\n",
    "    ges = [text[1].find(\"span\").text]\n",
    "    data = dpe + ges\n",
    "    return data\n",
    "\n",
    "# e) Meublé\n",
    "# Sur chaque annonce meublé, il y a une petite bulle en haut à gauche qui indique 'location meublée'. Donc il faut regardé\n",
    "# si cela apparait.\n",
    "def get_meuble_nexity(soup):\n",
    "    capsule = soup.find_all(\"div\", class_='flap flap--not-new')\n",
    "    if (capsule=='location meublée')==True:\n",
    "        meuble = \"oui\"\n",
    "    else:\n",
    "        meuble = \"non\"\n",
    "    return [meuble]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd27453",
   "metadata": {},
   "source": [
    "## 2. Fonction pour une annonce Nexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746cbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui nous donne toutes les caractéristiques d'une annonce nexity à l'aide des fonction précédente \n",
    "def get_nexity(urlpage):\n",
    "    user_agent = {'User-Agent':''}\n",
    "    soup = get_page(urlpage)\n",
    "    appart = []\n",
    "    appart = get_carac_nexity(soup, \"type\") + get_ville_nexity(soup) + get_quartier_nexity(soup) +  get_carac_nexity(soup, \"loyer\")  + get_carac_nexity(soup, \"charge\") + get_carac_nexity(soup, \"pièce\") + get_carac_nexity(soup, \"surface\") + get_meuble_nexity(soup) + get_carac_nexity(soup, \"ascenseur\") + get_carac_nexity(soup, \"balcon\") + get_carac_nexity(soup, \"terrain\") + get_carac_nexity(soup, \"terrasse\") + get_carac_nexity(soup, \"parking\") + get_carac_nexity(soup, \"cave\") + get_carac_nexity(soup, \"etage\") + get_nrj_nexity(soup)\n",
    "    return appart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c71a2",
   "metadata": {},
   "source": [
    "# IV. Fonction pour toutes les annonces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13196d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui reprend toutes les fonctions précédentes pour faire une fonction qui fait tout !\n",
    "def get_appart(site):\n",
    "    links = get_link(site)\n",
    "    var = [\"Type\", \"Ville\", \"Quartier\", \"Loyer\", \"Charges\", \"Pièces\", \"Surface\", \"Meublé\", \"Ascenseur\", \"Balcon\", \"Terrain extérieur\", \"Terrasse\", \"Parking\", \"Cave\", \"Étage\", \"Conso NRJ\", \"Conso GES\"]\n",
    "    data = pd.DataFrame([], columns=var)\n",
    "    if (site==\"orpi\")==True:\n",
    "        for i in range(len(links)):\n",
    "            info = get_orpi(links[i])\n",
    "            new_lines = pd.DataFrame([info], columns=var)\n",
    "            data = pd.concat([data, new_lines], ignore_index=True)\n",
    "    if (site==\"nexity\")==True:\n",
    "        for i in range(len(links)):\n",
    "            if (links[i].find(\"residence_etudiant\") != -1)==False:\n",
    "                info = get_nexity(links[i])\n",
    "                new_lines = pd.DataFrame([info], columns=var)\n",
    "                data = pd.concat([data, new_lines], ignore_index=True)\n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df869c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_appart(\"orpi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afd301",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_appart(\"nexity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd06c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([get_appart(\"nexity\"), get_appart(\"orpi\")], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312af21",
   "metadata": {},
   "source": [
    "# III. Scraping Nouveau Site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03829311",
   "metadata": {},
   "source": [
    "## 1. Fonctions pour les caractéristiques des annonces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
